# End-to-End Data Engineering Pipeline: Social Inequality in Spain

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/)
[![CI/CD](https://img.shields.io/badge/GitHub%20Actions-Matrix%20Testing-2ea44f)](https://github.com/features/actions)
[![Quality Gate](https://img.shields.io/badge/Code%20Quality-Strict-red)](https://flake8.pycqa.org/en/latest/)
[![SQL Server](https://img.shields.io/badge/DB-SQL%20Server%20ODBC%2018-lightgrey)]()

[ğŸ‡ºğŸ‡¸ English](#-english-version) | [ğŸ‡ªğŸ‡¸ EspaÃ±ol](#-versiÃ³n-en-espaÃ±ol)

---

## ğŸ‡ºğŸ‡¸ English Version

> **Overview:** Production-grade modular ETL pipeline designed for ingestion, transformation, and validation of socioeconomic data (INE and EUROSTAT). The project simulates a real business environment prioritizing robustness, data quality, and DevOps automation.

### ğŸ§  Engineering & Architecture Decisions

This project is not just a data science script; it is an implementation of software engineering applied to data.

#### 1. âš™ï¸ Modular & Resilient ETL Architecture

The system strictly decouples responsibilities to ensure maintainability and testability:

```mermaid
flowchart TD
  INE[INE] --> Extract
  EUROSTAT[Eurostat] --> Extract
  Extract --> Transform
  Transform --> Load
  Load --> SQLServer
  INE_VALID[INE Validation] -.-> INE
  EUROSTAT_VALID[EUROSTAT Validation] -.-> EUROSTAT
  INTEGRACION_VALID[Integration Validation] -.-> Load
  INE_VALID --> Logs
  EUROSTAT_VALID --> Logs
  INTEGRACION_VALID --> Logs
```

**Key Design Points:**
**Modular Validation:**
- Validation is performed in specific notebooks:
  - `02a_validacion_INE.ipynb`: validates INE tables according to declarative rules.
  - `02b_validacion_EUROSTAT.ipynb`: validates EUROSTAT tables according to declarative rules.
  - `02c_validacion_integracion.ipynb`: validates coherence between INE and EUROSTAT sources.
- Reports are saved in `data/validated/logs/` and do not affect the original load.
- Tables are not automatically validated upon upload; the process is explicit and modular.

#### 2. ğŸ›  Advanced DevOps & CI/CD (GitHub Actions)

Continuous integration pipeline designed for hybrid environments with enterprise robustness:

- **Matrix Testing:** ODBC drivers dynamically installed on **Ubuntu** and **Windows Server**.
- **Secret & Environment Management:** Conditional logic to adapt execution based on the environment.
- **Mandatory Quality Gates:**
  - `Black` â€“ PEP 8 Formatting
  - `Flake8` â€“ Linting
  - `MyPy` â€“ Static Typing
  - `Pytest` â€“ Unit Tests

#### 3. ğŸ”’ Security & Connectivity

- **ODBC Driver 18:** Compatibility with OpenSSL 3 (Ubuntu 24.04 / Azure).
- **Encryption in Transit:** Use of `TrustServerCertificate` and secure connection string configuration.
- **Secret Management via GitHub Actions + .env**

### ğŸ§° Tech Stack

| Area | Tools |
|------|-------|
| **Language** | Python 3.11+ (Pandas, NumPy, PyODBC, Requests) |
| **Orchestration & CI** | GitHub Actions (Matrix Strategy) |
| **Database** | SQL Server (Azure/Local), T-SQL |
| **Quality & Testing** | Pytest, Flake8, Black, MyPy, Validation Framework |
| **Infrastructure** | Docker (optional), virtual environments |

### ğŸ“ Project Structure

```text
desigualdad_social_etl/
â”œâ”€â”€ .github/workflows/           # ğŸ¤– CI/CD Pipelines (Matrix testing, Linting)
â”œâ”€â”€ src/                         # ğŸ§  Modular business logic
â”‚   â”œâ”€â”€ extractors/              # Connectors to APIs (Eurostat) and files (INE)
â”‚   â”œâ”€â”€ loaders/                 # Idempotent load to SQL Server
â”‚   â”œâ”€â”€ utils/                   # Transversal utilities
â”‚   â””â”€â”€ validation_framework.py  # Custom validation engine
â”œâ”€â”€ notebooks/                   # ğŸ““ ETL and analysis
â”‚   â”œâ”€â”€ 00_etl/                  # Ingestion and transformation pipelines
â”‚   â”œâ”€â”€ 01_analisis_nacional/    # Data Science
â”‚   â””â”€â”€ 06_sintesis/             # Executive reports
â”œâ”€â”€ tests/                       # âœ… Unit and integration tests
â”œâ”€â”€ docs/                        # ğŸ“š Technical and functional documentation
â”œâ”€â”€ scripts/                     # ğŸ”§ Maintenance scripts
â””â”€â”€ requirements.txt             # ğŸ“¦ Dependencies
```

### âš¡ Quick Start

#### 1. Environment Setup

```bash
# Clone and activate environment
git clone https://github.com/your-user/Desigualdad-Espana.git
cd Desigualdad-Espana
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

#### 2. Environment Variables (`.env`)

```env
DB_CONNECTION_STRING="DRIVER={ODBC Driver 18 for SQL Server};SERVER=localhost;DATABASE=desigualdad;Trusted_Connection=yes;TrustServerCertificate=yes;"
```

> **Note:** Double quotes around the connection string help preserve special characters when exporting the variable in different shells.

#### 3. Pipeline Execution

```bash
# Full Execution (E-T-L)
python notebooks/00_etl/01_run_etl.py

# Data Validation
python notebooks/00_etl/02_run_validation.py
```

### ğŸ“Š Impact & Results

The pipeline processes and consolidates **30 analytical tables** with critical indicators (AROPE, Gini, CPI).
**99.5%** coherence guaranteed between national (INE) and European (Eurostat) sources.

ğŸ“Œ More details in:
`docs/DICCIONARIO_DATOS.md`

### ğŸ“¬ Contact

This project demonstrates real capabilities of **Data Engineering + Data Quality + CI/CD**.

**Author:** Mario
**Focus:** Data Engineering, Data Quality, DevOps

---
---

## ğŸ‡ªğŸ‡¸ VersiÃ³n en EspaÃ±ol

> **VisiÃ³n General:** Pipeline ETL modular de nivel productivo diseÃ±ado para ingesta, transformaciÃ³n y validaciÃ³n de datos socioeconÃ³micos (INE y EUROSTAT). El proyecto simula un entorno empresarial real priorizando la robustez, la calidad del dato y la automatizaciÃ³n DevOps.

### ğŸ§  IngenierÃ­a y Decisiones de Arquitectura

Este proyecto no es solo un script de ciencia de datos; es una implementaciÃ³n de ingenierÃ­a de software aplicada a datos.

#### 1. âš™ï¸ Arquitectura ETL Modular y Resiliente

El sistema desacopla estrictamente las responsabilidades para garantizar mantenibilidad y testabilidad:

```mermaid
flowchart TD
  INE[INE] --> Extract
  EUROSTAT[Eurostat] --> Extract
  Extract --> Transform
  Transform --> Load
  Load --> SQLServer
  INE_VALID[ValidaciÃ³n INE] -.-> INE
  EUROSTAT_VALID[ValidaciÃ³n EUROSTAT] -.-> EUROSTAT
  INTEGRACION_VALID[ValidaciÃ³n IntegraciÃ³n] -.-> Load
  INE_VALID --> Logs
  EUROSTAT_VALID --> Logs
  INTEGRACION_VALID --> Logs
```

**Puntos clave del diseÃ±o:**
**ValidaciÃ³n Modular:**
- La validaciÃ³n se realiza en notebooks especÃ­ficos:
  - `02a_validacion_INE.ipynb`: valida tablas INE segÃºn reglas declarativas.
  - `02b_validacion_EUROSTAT.ipynb`: valida tablas EUROSTAT segÃºn reglas declarativas.
  - `02c_validacion_integracion.ipynb`: valida coherencia entre fuentes INE y EUROSTAT.
- Los reportes se guardan en `data/validated/logs/` y no afectan la carga original.
- No se valida automÃ¡ticamente todas las tablas al subir datos; el proceso es explÃ­cito y modular.

#### 2. ğŸ›  DevOps y CI/CD Avanzado (GitHub Actions)

Pipeline de integraciÃ³n continua diseÃ±ado para entornos hÃ­bridos con robustez empresarial:

- **Matrix Testing:** Drivers ODBC instalados dinÃ¡micamente en **Ubuntu** y **Windows Server**.
- **GestiÃ³n de secretos y entornos:** LÃ³gica condicional para adaptar la ejecuciÃ³n segÃºn entorno.
- **Quality Gates obligatorios:**
  - `Black` â€“ Formateo PEP 8
  - `Flake8` â€“ Linting
  - `MyPy` â€“ Tipado estÃ¡tico  
  - `Pytest` â€“ Tests unitarios

#### 3. ğŸ”’ Seguridad y Conectividad

- **ODBC Driver 18:** Compatibilidad con OpenSSL 3 (Ubuntu 24.04 / Azure).
- **EncriptaciÃ³n en trÃ¡nsito:** Uso de `TrustServerCertificate` y configuraciÃ³n segura de cadena de conexiÃ³n.
- **GestiÃ³n de secretos vÃ­a GitHub Actions + .env**

### ğŸ§° Stack TecnolÃ³gico

| Ãrea | Herramientas |
|------|---------------|
| **Lenguaje** | Python 3.11+ (Pandas, NumPy, PyODBC, Requests) |
| **OrquestaciÃ³n & CI** | GitHub Actions (Matrix Strategy) |
| **Base de Datos** | SQL Server (Azure/Local), T-SQL |
| **Calidad & Testing** | Pytest, Flake8, Black, MyPy, Validation Framework |
| **Infraestructura** | Docker (opcional), entornos virtuales |

### ğŸ“ Estructura del Proyecto

```text
desigualdad_social_etl/
â”œâ”€â”€ .github/workflows/           # ğŸ¤– CI/CD Pipelines (Matrix testing, Linting)
â”œâ”€â”€ src/                         # ğŸ§  LÃ³gica de negocio modular
â”‚   â”œâ”€â”€ extractors/              # Conectores a APIs (Eurostat) y ficheros (INE)
â”‚   â”œâ”€â”€ loaders/                 # Carga idempotente a SQL Server
â”‚   â”œâ”€â”€ utils/                   # Utilidades transversales
â”‚   â””â”€â”€ validation_framework.py  # Motor de validaciÃ³n custom
â”œâ”€â”€ notebooks/                   # ğŸ““ ETL y anÃ¡lisis
â”‚   â”œâ”€â”€ 00_etl/                  # Pipelines de ingesta y transformaciÃ³n
â”‚   â”œâ”€â”€ 01_analisis_nacional/    # Ciencia de datos
â”‚   â””â”€â”€ 06_sintesis/             # Informes ejecutivos
â”œâ”€â”€ tests/                       # âœ… Tests unitarios e integraciÃ³n
â”œâ”€â”€ docs/                        # ğŸ“š DocumentaciÃ³n tÃ©cnica y funcional
â”œâ”€â”€ scripts/                     # ğŸ”§ Scripts de mantenimiento
â””â”€â”€ requirements.txt             # ğŸ“¦ Dependencias
```

### âš¡ Quick Start

#### 1. PreparaciÃ³n del entorno

```bash
# Clonar y activar entorno
git clone https://github.com/tu-usuario/Desigualdad-Espana.git
cd Desigualdad-Espana
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

#### 2. Variables de Entorno (`.env`)

```env
DB_CONNECTION_STRING="DRIVER={ODBC Driver 18 for SQL Server};SERVER=localhost;DATABASE=desigualdad;Trusted_Connection=yes;TrustServerCertificate=yes;"
```

> **Nota:** las comillas dobles alrededor de la cadena de conexiÃ³n ayudan a preservar caracteres especiales al exportar la variable en distintos shells.

#### 3. EjecuciÃ³n del Pipeline

```bash
# EjecuciÃ³n completa (E-T-L)
python notebooks/00_etl/01_run_etl.py

# ValidaciÃ³n de datos
python notebooks/00_etl/02_run_validation.py
```

### ğŸ“Š Impacto y Resultados

El pipeline procesa y consolida **30 tablas analÃ­ticas** con indicadores crÃ­ticos (AROPE, Gini, IPC).
Se garantiza una coherencia del **99.5%** entre fuentes nacionales (INE) y europeas (Eurostat).

ğŸ“Œ MÃ¡s detalles en:
`docs/DICCIONARIO_DATOS.md`

### ğŸ“¬ Contacto

Este proyecto demuestra capacidades reales de **Data Engineering + Data Quality + CI/CD**.

**Autor:** Mario
**Enfoque:** IngenierÃ­a de Datos, Calidad del Dato, DevOps

---

## ğŸ“„ Licencia

Este proyecto es de cÃ³digo abierto y estÃ¡ disponible bajo la licencia **MIT**.
