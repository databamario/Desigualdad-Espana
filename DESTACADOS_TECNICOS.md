# üöÄ Destacados T√©cnicos: Pipeline ETL de Desigualdad Social

Este documento resume las decisiones de arquitectura, ingenier√≠a y DevOps implementadas en este proyecto. Est√° dise√±ado para ofrecer una visi√≥n r√°pida de la profundidad t√©cnica y las competencias en Ingenier√≠a de Datos aplicadas.

## 1. DevOps y CI/CD Avanzado (GitHub Actions)
El pipeline de Integraci√≥n Continua no es solo un ejecutor de scripts, sino una pieza de ingenier√≠a robusta dise√±ada para entornos h√≠bridos.

*   **Matriz de Ejecuci√≥n Multiplataforma**: 
    > *"Dise√±√© una matriz de pruebas que aprovisiona expl√≠citamente los drivers ODBC tanto en entornos **Ubuntu** como **Windows Server**, garantizando que el ETL es agn√≥stico al sistema operativo del despliegue."*
*   **Gesti√≥n Inteligente de Secretos**: Implementaci√≥n de l√≥gica condicional (`if: env.SKIP_DB_LOAD != 'true'`) que detecta autom√°ticamente si el entorno tiene acceso a la base de datos (Prod/Local) o es un entorno vol√°til (CI), adaptando el flujo de ejecuci√≥n sin romper el pipeline.
*   **Quality Gates Automatizados**: El c√≥digo no entra a producci√≥n si no pasa los est√°ndares de:
    *   **Black**: Formateo estricto de c√≥digo (PEP 8).
    *   **Flake8**: Detecci√≥n de errores l√≥gicos y de estilo.
    *   **MyPy**: Chequeo de tipado est√°tico para prevenir errores en tiempo de ejecuci√≥n.

## 2. Ingenier√≠a de Datos y Arquitectura ETL
El sistema est√° construido sobre Python y SQL Server, priorizando la mantenibilidad y la robustez.

*   **Arquitectura Modular**: Separaci√≥n estricta de responsabilidades (Extract, Transform, Load, Validate). Cada etapa es independiente y testeable.
*   **Conectividad SQL Robusta**: 
    *   Migraci√≥n a **ODBC Driver 18** para compatibilidad con los √∫ltimos est√°ndares de seguridad (Ubuntu 24.04 / OpenSSL 3).
    *   Manejo de cadenas de conexi√≥n seguras con soporte para `TrustServerCertificate` y encriptaci√≥n.
*   **Idempotencia y Recuperaci√≥n**: Los procesos de carga est√°n dise√±ados para ser re-ejecutables sin duplicar datos ni generar inconsistencias.

## 3. Framework de Calidad del Dato (Data Quality)
No solo muevo datos, aseguro su fiabilidad mediante un framework de validaci√≥n personalizado.

*   **Validaci√≥n Sem√°ntica y Estructural**: Scripts automatizados que verifican:
    *   **Integridad de Esquema**: Tipos de datos y columnas esperadas.
    *   **Reglas de Negocio**: Rangos v√°lidos para indicadores (ej. Gini 0-100, Tasas de desempleo).
    *   **Continuidad Temporal**: Detecci√≥n de huecos (*gaps*) en series temporales anuales.
*   **Reporting de Errores**: Generaci√≥n de logs detallados que permiten identificar la ra√≠z de los problemas de calidad en origen (INE/Eurostat).

## 4. Valor que Aporto al Equipo
Este proyecto demuestra mi capacidad para:
*   üèóÔ∏è **Construir Infraestructura S√≥lida**: No solo escribo scripts, creo sistemas que sobreviven a cambios de entorno y actualizaciones de dependencias.
*   üõ°Ô∏è **Priorizar la Calidad**: Automatizo el testing y el linting para que el equipo se centre en la l√≥gica de negocio, no en corregir espacios o imports.
*   üîÑ **Automatizar Todo**: Desde la instalaci√≥n de dependencias del sistema (apt-get/choco) hasta el despliegue y validaci√≥n de datos.
