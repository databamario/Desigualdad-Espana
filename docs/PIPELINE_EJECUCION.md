# ðŸš€ GuÃ­a de EjecuciÃ³n del Pipeline de AnÃ¡lisis

## Arquitectura de 3 Capas

Este proyecto sigue una arquitectura modular de 3 capas:

```
0. ETL (IngenierÃ­a) â†’ 1. ValidaciÃ³n â†’ 2. AnÃ¡lisis â†’ 3. Reporte
```

## EjecuciÃ³n RÃ¡pida

### Ejecutar todo el pipeline

```bash
make all
```

Esto ejecutarÃ¡ en orden:
1. ETL y preparaciÃ³n de datos
2. ValidaciÃ³n de calidad
3. AnÃ¡lisis de indicadores (Gini, AROPE, InflaciÃ³n)
4. GeneraciÃ³n del reporte final

### Ejecutar pasos individuales

```bash
# Solo ETL
make etl

# Solo validaciÃ³n
make validate

# Solo anÃ¡lisis
make analyze

# Solo reporte
make report
```

## Estructura de Archivos Intermedios

```
data/
  â”œâ”€â”€ processed/
  â”‚   â””â”€â”€ df_limpio.parquet          # DataFrame limpio (salida de ETL)
  â”œâ”€â”€ validated/
  â”‚   â””â”€â”€ validation_report.txt      # Reporte de validaciÃ³n
outputs/
  â”œâ”€â”€ resultados_gini_s80s20.parquet # Resultados de anÃ¡lisis principal
  â”œâ”€â”€ resultados_inflacion_diferencial.parquet
  â””â”€â”€ figuras/                       # GrÃ¡ficos generados
```

## Esquema de Datos

Ver `config/schema.yaml` para la especificaciÃ³n completa del DataFrame limpio.

Columnas principales:
- `AÃ±o`: AÃ±o de observaciÃ³n (2008-2023)
- `Gini`: Coeficiente de Gini
- `S80S20`: Ratio renta ricos/pobres
- `AROPE_%`: Tasa de riesgo de pobreza
- `Umbral_Real_â‚¬_Base`: Umbral ajustado por inflaciÃ³n

## Tests AutomÃ¡ticos

### Ejecutar tests

```bash
# Todos los tests
pytest

# Solo tests unitarios rÃ¡pidos
pytest -m unit

# Con cobertura
pytest --cov=src --cov-report=html
```

### Tests disponibles

- **DeflactaciÃ³n**: Verifica cÃ¡lculo correcto de valores reales
- **ValidaciÃ³n**: Comprueba detecciÃ³n de nulos y rangos
- **Indicadores**: Valida cÃ¡lculo de Gini, S80/S20, AROPE
- **Consistencia**: Verifica correlaciones entre indicadores
- **Integridad**: Comprueba continuidad temporal y ausencia de duplicados

## Notebooks por Capa

### Capa 0: ETL (00_etl/)
- `01_run_etl.py`: Script principal de extracciÃ³n y transformaciÃ³n
- Salida: `data/processed/df_limpio.parquet`

### Capa 1: ValidaciÃ³n
- `01_validacion_datos.ipynb`: ValidaciÃ³n de calidad de datos
- Salida: `data/validated/validation_report.txt`

### Capa 2: AnÃ¡lisis
- `02_analisis_indicadores_principales.ipynb`: Gini, S80/S20, AROPE
- `03_analisis_inflacion_diferencial.ipynb`: AnÃ¡lisis detallado de inflaciÃ³n
- Salida: Archivos parquet en `outputs/`

### Capa 3: Reporte
- `99_reporte_final.ipynb`: Narrativa y visualizaciÃ³n (sin cÃ¡lculos)

## ActualizaciÃ³n de Datos

Cuando los datos fuente cambien:

```bash
# Limpiar archivos intermedios
make clean

# Re-ejecutar todo el pipeline
make all
```

## Troubleshooting

### Error: "df_limpio.parquet no encontrado"
â†’ Ejecuta primero `make etl`

### Error: "ValidaciÃ³n fallÃ³"
â†’ Revisa `data/validated/validation_report.txt` para detalles

### Tests fallan
â†’ Ejecuta `pytest -v` para ver detalles especÃ­ficos

## Dependencias de EjecuciÃ³n

AsegÃºrate de tener instalado:
- Python >= 3.9
- Paquetes: pandas, numpy, matplotlib, seaborn, pyarrow, pytest
- Jupyter Notebook

Instalar dependencias:
```bash
pip install -r requirements.txt
```

## Buenas PrÃ¡cticas

âœ… **Siempre ejecuta el pipeline completo** despuÃ©s de cambios en ETL
âœ… **Revisa el reporte de validaciÃ³n** antes de confiar en los resultados
âœ… **Ejecuta los tests** antes de hacer commit de cambios
âœ… **Documenta** cualquier cambio en `config/schema.yaml` si modificas el esquema

## Contacto y Soporte

Para preguntas sobre el pipeline: consultar `docs/ARQUITECTURA.md`
